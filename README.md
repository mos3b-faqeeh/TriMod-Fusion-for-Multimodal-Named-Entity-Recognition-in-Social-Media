# TriMod-Fusion-for-Multimodal-Named-Entity-Recognition-in-Social-Media
Social media content presents challenges for Named Entity Recognition (NER) due to its informal and ambiguous nature. Traditional models struggle with this, prompting research into multimodal approaches that integrate text and images. However, existing methods fail to effectively align visual and textual entities. In this paper, we propose TriMod, a novel Transformer-based model that fuses textual, visual, and hashtag features for improved NER. Experiments on a multimodal dataset show that TriMod outperforms state-of-the-art methods, achieving higher precision, recall, and F1 scores.




In this repo, we have the two Datasets and Codes for our CASCON'2024 paper: TriMod Fusion for Multimodal Named Entity Recognition in Social Media.

Author

Mosab Alfaqeeh
18mmoa@queensu.ca
Nov 1, 2024
